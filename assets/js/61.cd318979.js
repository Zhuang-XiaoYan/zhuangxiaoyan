(window.webpackJsonp=window.webpackJsonp||[]).push([[61],{651:function(t,a,s){"use strict";s.r(a);var e=s(25),n=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"分布式限流原理与设计"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分布式限流原理与设计"}},[t._v("#")]),t._v(" 分布式限流原理与设计")]),t._v(" "),s("p",[t._v("针对软件系统来说，限流就是对请求的速率进行限制，避免瞬时的大量请求击垮软件系统。毕竟，软件系统的处理能力是有限的。\n如果说超过了其处理能力的范围，软件系统可能直接就挂掉了。限流可能会导致用户的请求无法被正确处理，不过，\n这往往也是权衡了软件系统的稳定性之后得到的最优解。现实生活中，处处都有限流的实际应用，就比如排队买票是为了避免大量用户涌入购票而导致售票员无法处理。")]),t._v(" "),s("h2",{attrs:{id:"限流指标"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#限流指标"}},[t._v("#")]),t._v(" 限流指标")]),t._v(" "),s("p",[t._v("目前主流的限流方法多采用 HPS 作为限流指标。")]),t._v(" "),s("ul",[s("li",[t._v("TPS（Transactions Per Second）是指每秒事务数。一个事务是指事务内第一个请求发送到接收到最后一个请求的响应的过程，以此来计算使用的时间和完成的事务个数。")]),t._v(" "),s("li",[t._v("QPS（Queries Per Second）是指每秒查询率。是一台服务器每秒能够响应的查询次数（数据库中的每秒执行查询sql的次数），显然这个不够全面，不能描述增删改，所以不建议用QPS来作为系统性能指标。")]),t._v(" "),s("li",[t._v("HPS（Hits Per Second）指每秒点击次数（每秒钟服务端收到客户端的请求数量） 。是指在一秒钟的时间内用户对Web页面的链接、提交按钮等点击总和。 它一般和TPS成正比关系，是B/S系统中非常重要的性能指标之一。")])]),t._v(" "),s("h2",{attrs:{id:"分流的方案"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分流的方案"}},[t._v("#")]),t._v(" 分流的方案")]),t._v(" "),s("p",[t._v("合法性验证限流：比如验证码、IP 黑名单等，这些手段可以有效的防止恶意攻击和爬虫采集；\n容器限流：比如 Tomcat、Nginx 等限流手段，其中 Tomcat 可以设置最大线程数（maxThreads），当并发超过最大线程数会排队等待执行；而 Nginx 提供了两种限流手段：一是控制速率，二是控制并发连接数；\n服务端限流：比如我们在服务器端通过限流算法实现限流。")]),t._v(" "),s("h2",{attrs:{id:"常见限流算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#常见限流算法"}},[t._v("#")]),t._v(" 常见限流算法")]),t._v(" "),s("h3",{attrs:{id:"固定窗口计数器算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#固定窗口计数器算法"}},[t._v("#")]),t._v(" 固定窗口计数器算法")]),t._v(" "),s("p",[t._v("固定窗口其实就是时间窗口。固定窗口计数器算法 规定了我们单位时间处理的请求数量。")]),t._v(" "),s("p",[t._v("假如我们规定系统中某个接口 1 分钟只能访问 33 次的话，使用固定窗口计数器算法的实现思路如下：")]),t._v(" "),s("ul",[s("li",[t._v("给定一个变量 counter 来记录当前接口处理的请求数量，初始值为 0（代表接口当前 1 分钟内还未处理请求）。")]),t._v(" "),s("li",[t._v("1 分钟之内每处理一个请求之后就将 counter+1 ，当 counter=33 之后（也就是说在这 1 分钟内接口已经被访问 33 次的话），")]),t._v(" "),s("li",[t._v("后续的请求就会被全部拒绝。等到 1 分钟结束后，将 counter 重置 0，重新开始计数。")])]),t._v(" "),s("p",[s("strong",[t._v("这种限流算法无法保证限流速率，因而无法保证突然激增的流量。")])]),t._v(" "),s("p",[t._v("就比如说我们限制某个接口 1 分钟只能访问 1000 次，该接口的 QPS 为 500，前 55s 这个接口 1 个请求没有接收，后 1s 突然接收了 1000 个请求。\n然后，在当前场景下，这 1000 个请求在 1s 内是没办法被处理的，系统直接就被瞬时的大量请求给击垮了。")]),t._v(" "),s("img",{attrs:{src:t.$withBase("/interview/limit01.png"),alt:"limit01"}}),t._v(" "),s("h3",{attrs:{id:"滑动窗口计数器算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#滑动窗口计数器算法"}},[t._v("#")]),t._v(" 滑动窗口计数器算法")]),t._v(" "),s("p",[t._v("滑动窗口计数器算法 算的上是固定窗口计数器算法的升级版。滑动窗口计数器算法相比于固定窗口计数器算法的优化在于：它把时间以一定比例分片 。")]),t._v(" "),s("p",[t._v("例如我们的接口限流每分钟处理 60 个请求，我们可以把 1 分钟分为 60 个窗口。每隔 1 秒移动一次，每个窗口一秒只能处理 不大于 60(请求数)/60（窗口数）\n的请求， 如果当前窗口的请求计数总和超过了限制的数量的话就不再处理其他请求。很显然， 当滑动窗口的格子划分的越多，滑动窗口的滚动就越平滑，限流的统计就会越精确。")]),t._v(" "),s("img",{attrs:{src:t.$withBase("/interview/limit02.png"),alt:"limit02"}}),t._v(" "),s("h3",{attrs:{id:"漏桶算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#漏桶算法"}},[t._v("#")]),t._v(" 漏桶算法")]),t._v(" "),s("p",[t._v("我们可以把发请求的动作比作成注水到桶中，我们处理请求的过程可以比喻为漏桶漏水。\n我们往桶中以任意速率流入水，以一定速率流出水。当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。")]),t._v(" "),s("p",[t._v("如果想要实现这个算法的话也很简单，准备一个队列用来保存请求，然后我们定期从队列中拿请求来执行就好了（和消息队列削峰/限流的思想是一样的）。")]),t._v(" "),s("img",{attrs:{src:t.$withBase("/interview/limit03.png"),alt:"limit03"}}),t._v(" "),s("h3",{attrs:{id:"令牌桶算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#令牌桶算法"}},[t._v("#")]),t._v(" 令牌桶算法")]),t._v(" "),s("p",[t._v("令牌桶算法也比较简单。和漏桶算法算法一样，我们的主角还是桶（这限流算法和桶过不去啊）。不过现在桶里装的是令牌了，\n请求在被处理之前需要拿到一个令牌，请求处理完毕之后将这个令牌丢弃（删除）。我们根据限流大小，按照一定的速率往桶里添加令牌。\n如果桶装满了，就不能继续往里面继续添加令牌了。")]),t._v(" "),s("img",{attrs:{src:t.$withBase("/interview/limit04.png"),alt:"limit04"}}),t._v(" "),s("h2",{attrs:{id:"容器限流"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#容器限流"}},[t._v("#")]),t._v(" 容器限流")]),t._v(" "),s("p",[t._v("Tomcat 限流: Tomcat 8.5 版本的最大线程数在 conf/server.xml 配置中，如下所示")]),t._v(" "),s("div",{staticClass:"language-xml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-xml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("Connector")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("port")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("8080"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("protocol")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("HTTP/1.1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("connectionTimeout")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("20000"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("maxThreads")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("150"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("redirectPort")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("8443"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n")])])]),s("p",[t._v("其中 maxThreads 就是 Tomcat 的最大线程数，当请求的并发大于此值（maxThreads）时，请求就会排队执行，这样就完成了限流的目的。")]),t._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),s("p",[t._v("maxThreads 的值可以适当的调大一些，此值默认为 150（Tomcat 版本 8.5.42），但这个值也不是越大越好，要看具体的硬件配置，\n需要注意的是每开启一个线程需要耗用 1MB 的 JVM 内存空间用于作为线程栈之用，并且线程越多 GC 的负担也越重。\n最后需要注意一下，操作系统对于进程中的线程数有一定的限制，Windows 每个进程中的线程数不允许超过 2000，Linux 每个进程中的线程数不允许超过 1000。")])]),t._v(" "),s("p",[s("strong",[t._v("Nginx 限流: Nginx 提供了两种限流手段：一是控制速率，二是控制并发连接数。")])]),t._v(" "),s("p",[t._v("控制速率:")]),t._v(" "),s("div",{staticClass:"language-html extra-class"},[s("pre",{pre:!0,attrs:{class:"language-html"}},[s("code",[t._v("limit_req_zone $binary_remote_addr zone=mylimit:10m rate=2r/s;\nserver {\n    location / {\n        limit_req zone=mylimit;\n    }\n}\n")])])]),s("p",[t._v("以上配置表示，限制每个 IP 访问的速度为 2r/s，因为 Nginx 的限流统计是基于毫秒的，我们设置的速度是 2r/s，\n转换一下就是 500ms 内单个 IP 只允许通过 1 个请求，从 501ms 开始才允许通过第 2 个请求。")]),t._v(" "),s("p",[t._v("速率限制升级版：上面的速率控制虽然很精准但是应用于真实环境未免太苛刻了，真实情况下我们应该控制一个 IP 单位总时间内的总访问次数，\n而不是像上面那么精确但毫秒，我们可以使用 burst 关键字开启此设置，示例配置如下：")]),t._v(" "),s("div",{staticClass:"language-html extra-class"},[s("pre",{pre:!0,attrs:{class:"language-html"}},[s("code",[t._v("limit_req_zone $binary_remote_addr zone=mylimit:10m rate=2r/s;\nserver {\n    location / {\n        limit_req zone=mylimit burst=4;\n    }\n}\n")])])]),s("p",[t._v("burst=4 表示每个 IP 最多允许 4 个突发请求，如果单个 IP 在 10ms 内发送 6 次请求")]),t._v(" "),s("p",[s("strong",[t._v("控制并发数")])]),t._v(" "),s("div",{staticClass:"language-html extra-class"},[s("pre",{pre:!0,attrs:{class:"language-html"}},[s("code",[t._v("limit_conn_zone $binary_remote_addr zone=perip:10m;\nlimit_conn_zone $server_name zone=perserver:10m;\n    server {\n        ...\n        limit_conn perip 10;\n        limit_conn perserver 100;\n}\n")])])]),s("p",[t._v("其中 limit_conn perip 10 表示限制单个 IP 同时最多能持有 10 个连接；limit_conn perserver 100 表示 server 同时能处理并发连接的总数为 100 个")]),t._v(" "),s("h2",{attrs:{id:"分布式限流-分布式锁来实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分布式限流-分布式锁来实现"}},[t._v("#")]),t._v(" 分布式限流(分布式锁来实现)")]),t._v(" "),s("p",[t._v("分布式限流针对的分布式/微服务应用架构应用，在这种架构下，单机限流就不适用了，因为会存在多种服务，并且一种服务也可能会被部署多份。")]),t._v(" "),s("ul",[s("li",[t._v("借助中间件架限流：可以借助 Sentinel 或者使用 Redis+lua来自己实现对应的限流逻辑。")]),t._v(" "),s("li",[t._v("网关层限流：比较常用的一种方案，直接在网关层把限流给安排上了。不过，通常网关层限流通常也需要借助到中间件/框架。\n就比如 Spring Cloud Gateway 的分布式限流实现RedisRateLimiter就是基于 Redis+Lua 来实现的，\n再比如 Spring Cloud Gateway 还可以整合 Sentinel 来做限流。")])])])}),[],!1,null,null,null);a.default=n.exports}}]);